{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-27 13:32:55 WARN  SparkSession$Builder:66 - Using an existing SparkSession; some configuration may not take effect.\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@5d745659\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().appName(\"carprice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.log4j._\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.log4j._\n",
    "Logger.getLogger(\"org\").setLevel(Level.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements to setup ML for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.LinearRegression\r\n",
       "import org.apache.spark.ml.feature.{StringIndexer, VectorAssembler, OneHotEncoder}\r\n",
       "import org.apache.spark.ml.linalg.Vectors\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.ml.feature.{StringIndexer,VectorAssembler,OneHotEncoder}\n",
    "import org.apache.spark.ml.linalg.Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Spark to read in the carprices csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data: org.apache.spark.sql.DataFrame = [Car Model: string, Mileage: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = spark.read.options(Map((\"header\",\"true\"),(\"inferSchema\",\"true\"))).csv(\"carprices.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the count of the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Long = 13\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the count of the Dataframe by dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Long = 13\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.na.drop().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BMW X5,69000,18000,6]\n",
      "[BMW X5,35000,34000,3]\n",
      "[BMW X5,57000,26100,5]\n",
      "[BMW X5,22500,40000,2]\n",
      "[BMW X5,46000,31500,4]\n"
     ]
    }
   ],
   "source": [
    "for (row <- data.head(5)){\n",
    "    println(row)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------+-------------+--------+\n",
      "|Car Model            |Mileage|Sell Price($)|Age(yrs)|\n",
      "+---------------------+-------+-------------+--------+\n",
      "|BMW X5               |69000  |18000        |6       |\n",
      "|BMW X5               |35000  |34000        |3       |\n",
      "|BMW X5               |57000  |26100        |5       |\n",
      "|BMW X5               |22500  |40000        |2       |\n",
      "|BMW X5               |46000  |31500        |4       |\n",
      "|Audi A5              |59000  |29400        |5       |\n",
      "|Audi A5              |52000  |32000        |5       |\n",
      "|Audi A5              |72000  |19300        |6       |\n",
      "|Audi A5              |91000  |12000        |8       |\n",
      "|Mercedez Benz C class|67000  |22000        |6       |\n",
      "|Mercedez Benz C class|83000  |20000        |7       |\n",
      "|Mercedez Benz C class|79000  |21000        |7       |\n",
      "|Mercedez Benz C class|59000  |33000        |5       |\n",
      "+---------------------+-------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Car Model: string (nullable = true)\n",
      " |-- Mileage: integer (nullable = true)\n",
      " |-- Sell Price($): integer (nullable = true)\n",
      " |-- Age(yrs): integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|Car Model            |count|\n",
      "+---------------------+-----+\n",
      "|BMW X5               |5    |\n",
      "|Audi A5              |4    |\n",
      "|Mercedez Benz C class|4    |\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy(\"Car Model\").count().show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the categotical column `Car Model` from String type to Vector form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using String Indexer to convert categorical string columns to numerical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indexer: org.apache.spark.ml.feature.StringIndexer = strIdx_ba5f8db788f3\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val indexer = new StringIndexer().setInputCol(\"Car Model\").setOutputCol(\"Car_Model_Ind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using One Hot Encoder to convert categorical numeric type columns to Vector type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder: org.apache.spark.ml.feature.OneHotEncoder = oneHot_deb047784794\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val encoder = new OneHotEncoder().setInputCol(\"Car_Model_Ind\").setOutputCol(\"Car_Model_Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling all the features to a single vector column \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_5056228c6111\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val assembler = new VectorAssembler().setInputCols(Array(\"Mileage\",\"Age(yrs)\",\"Car_Model_Vec\")).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the resultant data into training data and testing data,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>\n",
    "<b>Training data is to train the model</b>\n",
    "<b>Testing data is to test the builted model</b>\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_data: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Car Model: string, Mileage: int ... 2 more fields]\r\n",
       "test_data: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Car Model: string, Mileage: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train_data,test_data) = data.randomSplit(Array(0.7,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+------------------+------------------+\n",
      "|summary|           Car Model|           Mileage|     Sell Price($)|          Age(yrs)|\n",
      "+-------+--------------------+------------------+------------------+------------------+\n",
      "|  count|                  13|                13|                13|                13|\n",
      "|   mean|                null| 60884.61538461538|26023.076923076922|5.3076923076923075|\n",
      "| stddev|                null|19185.665054663692| 8003.661021282057|1.6525039276108333|\n",
      "|    min|             Audi A5|             22500|             12000|                 2|\n",
      "|    max|Mercedez Benz C c...|             91000|             40000|                 8|\n",
      "+-------+--------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+-----------------+-----------------+\n",
      "|summary|           Car Model|           Mileage|    Sell Price($)|         Age(yrs)|\n",
      "+-------+--------------------+------------------+-----------------+-----------------+\n",
      "|  count|                   8|                 8|                8|                8|\n",
      "|   mean|                null|           58062.5|          26475.0|              5.0|\n",
      "| stddev|                null|21374.947786068224|9438.939105035663|1.851640199545103|\n",
      "|    min|             Audi A5|             22500|            12000|                2|\n",
      "|    max|Mercedez Benz C c...|             91000|            40000|                8|\n",
      "+-------+--------------------+------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+-----------------+------------------+\n",
      "|summary|           Car Model|         Mileage|    Sell Price($)|          Age(yrs)|\n",
      "+-------+--------------------+----------------+-----------------+------------------+\n",
      "|  count|                   5|               5|                5|                 5|\n",
      "|   mean|                null|         65400.0|          25300.0|               5.8|\n",
      "| stddev|                null|16226.5215003093|5932.958789676531|1.3038404810405297|\n",
      "|    min|             Audi A5|           46000|            20000|                 4|\n",
      "|    max|Mercedez Benz C c...|           83000|            32000|                 7|\n",
      "+-------+--------------------+----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Linear regression model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr: org.apache.spark.ml.regression.LinearRegression = linReg_3f3b311f0053\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lr = new LinearRegression().setLabelCol(\"Sell Price($)\").setFeaturesCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.Pipeline\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_6ce4c9b6893a\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipeline = new Pipeline().setStages(Array(indexer,encoder,assembler,lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the pipeline to training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-27 14:05:28 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2019-12-27 14:05:28 WARN  BLAS:61 - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "2019-12-27 14:05:28 WARN  LAPACK:61 - Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "2019-12-27 14:05:28 WARN  LAPACK:61 - Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pipelineModel: org.apache.spark.ml.PipelineModel = pipeline_6ce4c9b6893a\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipelineModel = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Results on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results: org.apache.spark.sql.DataFrame = [Car Model: string, Mileage: int ... 6 more fields]\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = pipelineModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+------------------+\n",
      "|features             |Sell Price($)|prediction        |\n",
      "+---------------------+-------------+------------------+\n",
      "|[52000.0,5.0,0.0,1.0]|32000        |33799.768697000574|\n",
      "|[46000.0,4.0,1.0,0.0]|31500        |29410.10023130288 |\n",
      "|[67000.0,6.0,0.0,0.0]|22000        |30638.357748654154|\n",
      "|[79000.0,7.0,0.0,0.0]|21000        |24599.92289900026 |\n",
      "|[83000.0,7.0,0.0,0.0]|20000        |20923.130300692224|\n",
      "+---------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select(\"features\",\"Sell Price($)\",\"prediction\").show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output: org.apache.spark.sql.DataFrame = [Car Model: string, Mileage: int ... 6 more fields]\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var output = pipelineModel.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res21: Long = 13\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Car Model: string (nullable = true)\n",
      " |-- Mileage: integer (nullable = true)\n",
      " |-- Sell Price($): integer (nullable = true)\n",
      " |-- Age(yrs): integer (nullable = true)\n",
      " |-- Car_Model_Ind: double (nullable = false)\n",
      " |-- Car_Model_Vec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output: org.apache.spark.sql.DataFrame = [Sell Price($): int, features: vector]\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output.select(\"Sell Price($)\",\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_data_2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Sell Price($): int, features: vector]\r\n",
       "test_data_2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Sell Price($): int, features: vector]\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train_data_2,test_data_2) = output.randomSplit(Array(0.7,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|     Sell Price($)|\n",
      "+-------+------------------+\n",
      "|  count|                13|\n",
      "|   mean|26023.076923076922|\n",
      "| stddev| 8003.661021282057|\n",
      "|    min|             12000|\n",
      "|    max|             40000|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|    Sell Price($)|\n",
      "+-------+-----------------+\n",
      "|  count|               10|\n",
      "|   mean|          25920.0|\n",
      "| stddev|8715.477930415265|\n",
      "|    min|            12000|\n",
      "|    max|            40000|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|     Sell Price($)|\n",
      "+-------+------------------+\n",
      "|  count|                 3|\n",
      "|   mean|26366.666666666668|\n",
      "| stddev| 6504.101270224299|\n",
      "|    min|             20000|\n",
      "|    max|             33000|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_2.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a linear regression model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr_2: org.apache.spark.ml.regression.LinearRegression = linReg_9fe28b98cee8\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lr_2 = new LinearRegression().setLabelCol(\"Sell Price($)\").setFeaturesCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a linear regression model and fitting the training data to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lrModel: org.apache.spark.ml.regression.LinearRegressionModel = linReg_9fe28b98cee8\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lrModel = lr_2.fit(train_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the training summary of the created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainingSummary: org.apache.spark.ml.regression.LinearRegressionTrainingSummary = org.apache.spark.ml.regression.LinearRegressionTrainingSummary@7f6fae47\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "| -594.1238001475867|\n",
      "| -599.0155057838274|\n",
      "|-1557.2298793995215|\n",
      "|  2393.551562884517|\n",
      "|-2393.5515628846406|\n",
      "|  2093.446960374051|\n",
      "| 1988.9982771351388|\n",
      "|  57.90671917310101|\n",
      "| -635.8848141767448|\n",
      "| -754.0979571745411|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingSummary.residuals.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1306.780703913367\n",
      "Mean Squared Error: 2390994.646812703\n",
      "Root Mean Squared Error: 1546.2841416805331\n",
      "R Squared Error: 0.9650253256584981\n"
     ]
    }
   ],
   "source": [
    "println(s\"Mean Absolute Error: ${trainingSummary.meanAbsoluteError}\")\n",
    "println(s\"Mean Squared Error: ${trainingSummary.meanSquaredError}\")\n",
    "println(s\"Root Mean Squared Error: ${trainingSummary.rootMeanSquaredError}\")\n",
    "println(s\"R Squared Error: ${trainingSummary.r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model against test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_results_2: org.apache.spark.ml.regression.LinearRegressionSummary = org.apache.spark.ml.regression.LinearRegressionSummary@1502f5d7\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val test_results_2 = lrModel.evaluate(test_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the co-effecients and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.6622200344572781,2159.537287718177,-4470.095988186261,-225.221511198732]\n",
      "Intercept: 55805.070145213205\n"
     ]
    }
   ],
   "source": [
    "println(s\"Coefficients: ${lrModel.coefficients}\")\n",
    "println(s\"Intercept: ${lrModel.intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         residuals|\n",
      "+------------------+\n",
      "| 4042.431700713627|\n",
      "|1713.8813684470188|\n",
      "| 5468.225449175319|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results_2.residuals.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model by checking the different types of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 3741.512839445322\n",
      "Mean Squared Error: 1.6393377654350972E7\n",
      "Root Mean Squared Error: 4048.873627856391\n",
      "R Squared Error: 0.4187203573825594\n"
     ]
    }
   ],
   "source": [
    "println(s\"Mean Absolute Error: ${test_results_2.meanAbsoluteError}\")\n",
    "println(s\"Mean Squared Error: ${test_results_2.meanSquaredError}\")\n",
    "println(s\"Root Mean Squared Error: ${test_results_2.rootMeanSquaredError}\")\n",
    "println(s\"R Squared Error: ${test_results_2.r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the predictions from the builted model without label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unlabelled_data: org.apache.spark.sql.DataFrame = [features: vector]\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val unlabelled_data = test_data_2.select(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions: org.apache.spark.sql.DataFrame = [features: vector, prediction: double]\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions = lrModel.transform(unlabelled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+\n",
      "|features             |prediction        |\n",
      "+---------------------+------------------+\n",
      "|[83000.0,7.0,0.0,0.0]|15957.568299286373|\n",
      "|[57000.0,5.0,1.0,0.0]|24386.11863155298 |\n",
      "|[59000.0,5.0,0.0,0.0]|27531.77455082468 |\n",
      "+---------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping the created spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
